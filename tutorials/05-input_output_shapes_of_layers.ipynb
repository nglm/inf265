{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 05 - Input and output shapes of neural network layers\n",
    "\n",
    "When defining neural networks, we have to make sure that consecutive layers are compatible. In practice, this basically means that the output shape of layer ``l`` is compatible with the input shape requirements of the layer ``l+1``. \n",
    "\n",
    "We introduced pytorch's standard dimension notations in the 2nd tutorial `02_using_nn_sequential_and_training_loop.ipynb`. Here, we will use a specific example to illustrate how important it is to:\n",
    "\n",
    "1. carefully read the documentation\n",
    "2. understand how input and output shapes are defined. \n",
    "\n",
    "You do not need to understand what is a convolutional layer nor a maxpool layer yet, you just need to read the documentation. We will study these layers in depth later on, so don't worry if you're struggling a bit now. If you are curious, you can still watch **Andrew Ng's videos about convolution and pooling for detailed info (especially from C4W1L02 to C4W1L11)**. But don't insist if it's more confusing than helpful for now! You can go back to this document once you are more familiar with deep learning concepts. :)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torchvision import datasets, transforms"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Designing a specific example\n",
    "\n",
    "### Loading data\n",
    "\n",
    "For this specific example will we use a (preprocessed) batch from the CIFAR dataset. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_CIFAR10(data_path='../data/', preprocessor=None):\n",
    "    \n",
    "    if preprocessor is None:\n",
    "        preprocessor = transforms.Compose([\n",
    "            transforms.CenterCrop((28, 32)),\n",
    "            transforms.ToTensor(),\n",
    "        ])\n",
    "    \n",
    "    data_train_val = datasets.CIFAR10(\n",
    "        data_path,       \n",
    "        train=True,      \n",
    "        download=True,\n",
    "        transform=preprocessor)\n",
    "    \n",
    "    return data_train_val\n",
    "\n",
    "data = load_CIFAR10()\n",
    "loader = torch.utils.data.DataLoader(data, batch_size=512, shuffle=False)\n",
    "\n",
    "# Take the first first batch of our dataset\n",
    "(batch, labels) = next(iter(loader))\n",
    "\n",
    "print(\"\\nShape of a batch for our specific example:\\n\", batch.shape)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Defining a neural network\n",
    "\n",
    "For this specific example we define a very simple convolutional network. Note that we don't use the functional API here for non-trainable layers such as MaxPool2d or Flatten. This is only for clarity purpose."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MyNet(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__() \n",
    "        self.conv1 = nn.Conv2d(in_channels=3, out_channels=16, kernel_size=(3, 4), padding=1)  \n",
    "        self.pool1 = nn.MaxPool2d(2)\n",
    "        self.conv2 = nn.Conv2d(16, 10, kernel_size=3)\n",
    "        self.pool2 = nn.MaxPool2d(2)\n",
    "        self.flat = nn.Flatten()\n",
    "        self.fc1 = nn.Linear(in_features=10 * 6 * 6, out_features=32)\n",
    "        self.fc2 = nn.Linear(32, 10)\n",
    "\n",
    "    def forward(self, x):\n",
    "        print(\"input shape:              \", x.shape)\n",
    "        \n",
    "        out = self.conv1(x)\n",
    "        print(\"After 1st convolution:    \", out.shape)\n",
    "        \n",
    "        out = torch.relu(self.pool1(out))\n",
    "        print(\"After 1st MaxPool2d:      \", out.shape)\n",
    "        \n",
    "        out = self.conv2(out)\n",
    "        print(\"After 2nd convolution:    \", out.shape)\n",
    "        \n",
    "        out = torch.relu(self.pool2(out))\n",
    "        print(\"After 2nd MaxPool2d:      \", out.shape)\n",
    "        \n",
    "        out = self.flat(out)\n",
    "        print(\"After flattening:         \", out.shape)\n",
    "        \n",
    "        out = torch.relu(self.fc1(out))\n",
    "        print(\"After 1st linear:         \", out.shape)\n",
    "        \n",
    "        out = self.fc2(out)\n",
    "        print(\"After 2nd linear:         \", out.shape)\n",
    "        return out\n",
    "    \n",
    "model = MyNet()\n",
    "out = model(batch)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Figuring out shapes when stacking layers\n",
    "\n",
    "### Shape of the data\n",
    "\n",
    "When defining `MyNet`, the objective is to deal with batches of size `N=512` of `28x32` RGB images, which means inputs are of dimensions ``(512, 3, 28, 32)``. There are 10 classes in this dataset so the output of `MyNet` must be of shape `(512, 10)`. Note that, in general `N` is not affected by layers nor activation functions.\n",
    "\n",
    "### 1st layer: Convolution, [nn.Conv2d](https://pytorch.org/docs/stable/generated/torch.nn.Conv2d.html#conv2d)\n",
    "\n",
    "Let's take a closer look at the following line (line 4 in the cell above):\n",
    "\n",
    "```python\n",
    "nn.Conv2d(in_channels=3, out_channels=16, kernel_size=(3, 4), padding=1)  \n",
    "```\n",
    "\n",
    "Here: \n",
    "- ``in_channels = 3`` because we have 3 channels in our data (RGB). You are not free to choose what you want here, it must correspond to the number of channels of this layer's input (which is here your data).\n",
    "- ``out_channels = 16`` You are free to choose what you want here, this corresponds to the number of convolutional filters in the layer. It also defines `C_out`.\n",
    "- ``kernel_size = (3, 4)`` The dimensions of your convolutional filters. You are free to choose what you want here, but it will affect the `H_out` and `W_out` of the output.\n",
    "- ``stride = 1`` (default value). You are free to choose what you want here, but affects `H_out` and `W_out` as well.\n",
    "- ``padding = 1`` You are free to choose what you want here also, but affects `H_out` and `W_out` as well.\n",
    "\n",
    "To compute the values of ``H_out`` and ``W_out`` we used the formula written in the documentation: \n",
    "\n",
    "$$H_{out} = int\\Big[ \\frac{H_{in} + 2*padding - kernel\\_size}{stride} + 1 \\Big]$$ \n",
    "$$W_{out} = int\\Big[ \\frac{W_{in} + 2*padding - kernel\\_size}{stride} + 1 \\Big]$$ \n",
    "\n",
    "Therefore, the input shape ``(N, C_in, H_in, W_in)`` of this layer is `(512, 3, 32, 32)` and the output shape ``(N, C_out, H_out, W_out)`` of this layer is `(512, 16, 28, 31)`. \n",
    "\n",
    "### Intermediate layer: MaxPool, [nn.MaxPool2d](https://pytorch.org/docs/stable/generated/torch.nn.MaxPool2d.html#maxpool2d)\n",
    "\n",
    "```python\n",
    "nn.MaxPool2d(2)  #line 5\n",
    "```\n",
    "\n",
    "Which means: \n",
    "\n",
    "- ``kernel_size=2`` The dimensions of your pooling filters. You are free to choose what you want here, but it will affect the `H_out` and `W_out` \n",
    "- ``stride=kernel_size`` (default value). You are free to choose what you want here, but it will affect the `H_out` and `W_out`. When ``stride=kernel_size``, the output dimensions `H_out` and `W_out` are the input dimensions `H_in` and `W_in` divided by ``kernel_size``. \n",
    "\n",
    "Therefore the input/output shapes are:\n",
    "\n",
    "- `(N, C_in, H_in, W_in) = (512, 16, 28, 31)`\n",
    "- `(N, C_out, H_out, W_out) = (512, 16, 14, 15)`\n",
    "\n",
    "Note that for a `nn.MaxPool2d` layer, there is no requirements on any of the shape variables `N, C_in, H_in, W_in` and that you are free to choose its parameters.\n",
    "\n",
    "### 2nd layer: Convolution again\n",
    "\n",
    "```python\n",
    "self.conv2 = nn.Conv2d(16, 10, kernel_size=3) #line 6\n",
    "```\n",
    "\n",
    "Which means:\n",
    "\n",
    "- ``in_channels = 16``. Which is indeed compatible with the previous layer where we had `C_out=16`.\n",
    "- ``out_channels = 10``, ``kernel_size = 3 ``, ``stride = 1 `` (default value),``padding = 1 `` Which we are all free to choose (but affects ``H_out`` and ``W_out``).\n",
    "\n",
    "Therefore the input/output shapes are:\n",
    "\n",
    "- `(N, C_in, H_in, W_in)=(512, 16, 14, 15)`\n",
    "- `(N, C_out, H_out, W_out)=(512, 10, 12, 13)`\n",
    "\n",
    "### 2nd Intermediate layer: MaxPool, [nn.MaxPool2d](https://pytorch.org/docs/stable/generated/torch.nn.MaxPool2d.html#maxpool2d)\n",
    "\n",
    "```python\n",
    "nn.MaxPool2d(2)  #line 7\n",
    "```\n",
    "\n",
    "Therefore the input/output shapes are:\n",
    "\n",
    "- `(N, C_in, H_in, W_in)=(512, 10, 12, 13)`\n",
    "- `(N, C_out, H_out, W_out)=(512, 10, 6, 6)`\n",
    "\n",
    "### 3rd layer: Fully connected layer [nn.Linear](https://pytorch.org/docs/stable/generated/torch.nn.Linear.html#linear)\n",
    "\n",
    "#### Flatten layer, [nn.Flatten](https://pytorch.org/docs/stable/generated/torch.nn.Flatten.html#flatten)\n",
    "\n",
    "This type of layer requires a different type of input shape: `(N, in_features)` and outputs batches of shape `(N, out_features)`. So the inputs must be flattened first, see line 8.\n",
    "\n",
    "So, for this layer we have as input dimension `(N, C_in, H_in, W_in)=(512, 10, 6, 6)`, and as output dimension `(N, out_features)=(512, 10*6*6)`\n",
    "\n",
    "#### Linear layer\n",
    "\n",
    "```python\n",
    "nn.Linear(in_features=10 * 6 * 6, out_features=32)  #line 9\n",
    "```\n",
    "\n",
    "Which means:\n",
    "\n",
    "- ``in_features = 10*6*6``. You are not free to choose what you want here, it must correspond to the number features of this layer's input (which is here the output of the flatten layer). This is indeed compatible with the previous layer where we had `out_features=10*6*6`.\n",
    "- ``out_features = 32``. You are free to choose what you want here.\n",
    "\n",
    "So, for this layer we have as input dimension `(N, in_features)=(512, 10*6*6)`, and as output dimension `(N, out_features)=(512, 32)`\n",
    "\n",
    "### 4th layer: Fully connected layer [nn.Linear](https://pytorch.org/docs/stable/generated/torch.nn.Linear.html#linear)\n",
    "\n",
    "```python\n",
    "self.fc1 = nn.Linear(32, 10) # line 10\n",
    "```\n",
    "\n",
    "Which means:\n",
    "\n",
    "- ``in_features = 32``. This is indeed compatible with the previous layer.\n",
    "- ``out_features = 10``. You are not free to choose what you want here because it is the last layer of your model. It must correspond to the classes in your dataset.\n",
    "\n",
    "Therefore the input/output shapes are:\n",
    "\n",
    "- `(N, in_features)=(512, 32)`\n",
    "- `(N, out_features)=(512, 10)`\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "inf265",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "d7334498cbea74be2f983349dd0c062cc89e10cb2d32c736100e0abee6e40bc2"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
