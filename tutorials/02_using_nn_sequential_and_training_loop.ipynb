{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 02 - Define, train and evaluate a basic Neural Network in Pytorch\n",
    "\n",
    "These tutorials are inspired by the book \"[Deep Learning with PyTorch](https://pytorch.org/assets/deep-learning/Deep-Learning-with-PyTorch.pdf)\" by Stevens et al and can be seen as a summary of the part I of the book regarding PyTorch itself. Normally, following the tutorials should be enough and reading the book is not required.\n",
    "\n",
    "## Contents\n",
    "\n",
    "1. Loading data  \n",
    "    1. Loading CIFAR-10  (see previous tutorial)  \n",
    "    2. From CIFAR-10 to CIFAR-2  \n",
    "2. Basic building blocks for neural networks in PyTorch  \n",
    "    1. The 'torch.nn' module and the 'torch.nn.Module' class  \n",
    "    2. Our network as a nn.Sequential object  \n",
    "    3. Pytorch notations and dimensions  \n",
    "    4. Inspecting a module object\n",
    "3. Training our model  \n",
    "    1. Training on CPU  \n",
    "    2. Training on GPU "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch._C.Generator at 0x7f015bfff730>"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torchvision import datasets, transforms\n",
    "from datetime import datetime\n",
    "from torch.utils.data import random_split\n",
    "\n",
    "torch.manual_seed(123)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Loading data\n",
    "\n",
    "### 1.1 Loading CIFAR-10  (see previous tutorial)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n",
      "Size of the train dataset:         45000\n",
      "Size of the validation dataset:    5000\n",
      "Size of the test dataset:          10000\n"
     ]
    }
   ],
   "source": [
    "def load_cifar(train_val_split=0.9, data_path='../data/', preprocessor=None):\n",
    "    \n",
    "    # Define preprocessor if not already given\n",
    "    if preprocessor is None:\n",
    "        preprocessor = transforms.Compose([\n",
    "            transforms.ToTensor(),\n",
    "            transforms.Normalize((0.4915, 0.4823, 0.4468),\n",
    "                                (0.2470, 0.2435, 0.2616))\n",
    "        ])\n",
    "    \n",
    "    # load datasets\n",
    "    data_train_val = datasets.CIFAR10(\n",
    "        data_path,       \n",
    "        train=True,      \n",
    "        download=True,  \n",
    "        transform=preprocessor)\n",
    "\n",
    "    data_test = datasets.CIFAR10(\n",
    "        data_path, \n",
    "        train=False,\n",
    "        download=True,\n",
    "        transform=preprocessor)\n",
    "\n",
    "    # train/validation split\n",
    "    n_train = int(len(data_train_val)*train_val_split)\n",
    "    n_val =  len(data_train_val) - n_train\n",
    "\n",
    "    data_train, data_val = random_split(\n",
    "        data_train_val, \n",
    "        [n_train, n_val],\n",
    "        generator=torch.Generator().manual_seed(123)\n",
    "    )\n",
    "\n",
    "    print(\"Size of the train dataset:        \", len(data_train))\n",
    "    print(\"Size of the validation dataset:   \", len(data_val))\n",
    "    print(\"Size of the test dataset:         \", len(data_test))\n",
    "    \n",
    "    return (data_train, data_val, data_test)\n",
    "\n",
    "cifar10_train, cifar10_val, cifar10_test = load_cifar()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.2 From CIFAR-10 to CIFAR-2\n",
    "\n",
    "We define a lighter version of CIFAR-10, which is now CIFAR-2, containing only the planes and birds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Size of the training dataset:  9017\n",
      "Size of the validation dataset:  983\n",
      "Size of the test dataset:  2000\n"
     ]
    }
   ],
   "source": [
    "label_map = {0: 0, 2: 1}\n",
    "class_names = ['airplane', 'bird']\n",
    "\n",
    "# For each dataset, keep only airplanes and birds\n",
    "cifar2_train = [(img, label_map[label]) for img, label in cifar10_train if label in [0, 2]]\n",
    "cifar2_val = [(img, label_map[label]) for img, label in cifar10_val if label in [0, 2]]\n",
    "cifar2_test = [(img, label_map[label]) for img, label in cifar10_test if label in [0, 2]]\n",
    "\n",
    "print('Size of the training dataset: ', len(cifar2_train))\n",
    "print('Size of the validation dataset: ', len(cifar2_val))\n",
    "print('Size of the test dataset: ', len(cifar2_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Basic building blocks for neural networks in PyTorch \n",
    "\n",
    "### 2.1 The 'torch.nn' module and the 'torch.nn.Module' class\n",
    "\n",
    "In Pytorch, the basic building blocks for neural networks are available in the [torch.nn](https://pytorch.org/docs/stable/nn.html) module (often imported as 'nn'). The base class for all the basic components of a neural network is then [nn.Module](https://pytorch.org/docs/stable/generated/torch.nn.Module.html)\n",
    "\n",
    "For example:\n",
    "\n",
    "- the [nn.ReLU](https://pytorch.org/docs/stable/generated/torch.nn.ReLU.html#torch.nn.ReLU) activation fonction is a subclass of the [nn.Module](https://pytorch.org/docs/stable/generated/torch.nn.Module.html) class\n",
    "- the 1D convolutional layer [nn.Conv1d](https://pytorch.org/docs/stable/generated/torch.nn.Conv1d.html#torch.nn.Conv1d) is a subclass of the [nn.Module](https://pytorch.org/docs/stable/generated/torch.nn.Module.html) class\n",
    "- the MSE loss function [nn.MSELoss](https://pytorch.org/docs/stable/generated/torch.nn.MSELoss.html#torch.nn.MSELoss) is a subclass of the [nn.Module](https://pytorch.org/docs/stable/generated/torch.nn.Module.html) class\n",
    "- the distance function [nn.PairwiseDistance ](https://pytorch.org/docs/stable/generated/torch.nn.PairwiseDistance.html#torch.nn.PairwiseDistance) is a subclass of the [nn.Module](https://pytorch.org/docs/stable/generated/torch.nn.Module.html) class\n",
    "- the container [nn.Sequential](https://pytorch.org/docs/stable/generated/torch.nn.Sequential.html#torch.nn.Sequential) (will see in the next cell what it is exactly)  is also a subclass of the [nn.Module](https://pytorch.org/docs/stable/generated/torch.nn.Module.html) class\n",
    "\n",
    "Exception: \n",
    "\n",
    "- [nn.Parameter](https://pytorch.org/docs/stable/generated/torch.nn.parameter.Parameter.html) is not a subclass of [nn.Module](https://pytorch.org/docs/stable/generated/torch.nn.Module.html) but of [torch.Tensor](https://pytorch.org/docs/stable/tensors.html#torch.Tensor) instead (the other extremely important class in PyTorch)\n",
    "\n",
    "So in short, almost everything in torch.nn can be seen as a nn.Module in PyTorch :) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Things implemented in nn.module inherit from the nn.Module class ---\n",
      "ReLU activation function:           True\n",
      "Conv1d layer:                       True\n",
      "MSELoss loss function:              True\n",
      "PairwiseDistance distance measure:  True\n",
      "Sequential (group of layers):       True\n",
      "\n",
      "--- nn.Parameter is not a subclass of nn.Module but of torch.Tensor instead ---\n",
      "nn.Parameter, subclass of nn.Module?     False\n",
      "nn.Parameter, subclass of torch.Tensor?  True\n"
     ]
    }
   ],
   "source": [
    "print(\"--- Things implemented in nn.module inherit from the nn.Module class ---\")\n",
    "print(\"ReLU activation function:          \", issubclass(nn.ReLU, nn.Module))\n",
    "print(\"Conv1d layer:                      \", issubclass(nn.Conv1d, nn.Module))\n",
    "print(\"MSELoss loss function:             \", issubclass(nn.MSELoss, nn.Module))\n",
    "print(\"PairwiseDistance distance measure: \", issubclass(nn.PairwiseDistance, nn.Module))\n",
    "print(\"Sequential (group of layers):      \", issubclass(nn.Sequential, nn.Module))\n",
    "print(\"\\n--- nn.Parameter is not a subclass of nn.Module but of torch.Tensor instead ---\")\n",
    "print(\"nn.Parameter, subclass of nn.Module?    \", issubclass(nn.Parameter, nn.Module))\n",
    "print(\"nn.Parameter, subclass of torch.Tensor? \", issubclass(nn.Parameter, torch.Tensor))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "### 2.2 Our network as a nn.Sequential object\n",
    "\n",
    "*(inspired by 6.3. Finally a neural network)*\n",
    "\n",
    "Now what is this \n",
    "*[nn.Sequential](https://pytorch.org/docs/stable/generated/torch.nn.Sequential.html#torch.nn.Sequential) container* thing? \n",
    "Well [nn.Sequential](https://pytorch.org/docs/stable/generated/torch.nn.Sequential.html#torch.nn.Sequential) provides a simple way to concatenate [nn.Module](https://pytorch.org/docs/stable/generated/torch.nn.Module.html) objects.\n",
    "\n",
    "Links to the documentation:\n",
    "- [nn.Flatten](https://pytorch.org/docs/stable/generated/torch.nn.Flatten.html#torch.nn.Flatten), flattens each input tensor\n",
    "- [nn.Linear](https://pytorch.org/docs/stable/generated/torch.nn.Linear.html#torch.nn.Linear), fully connected linear layer\n",
    "- [nn.Tanh](https://pytorch.org/docs/stable/generated/torch.nn.Tanh.html?highlight=tanh#torch.nn.Tanh), activation function\n",
    "- [nn.ReLU](https://pytorch.org/docs/stable/generated/torch.nn.ReLU.html?highlight=relu#torch.nn.ReLU), activation function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_in = 32*32*3   # Determined by our dataset: 32x32 RGB images\n",
    "n_hidden1 = 256  # Choose whatever you want here, often powers of 2\n",
    "n_hidden2 = 64\n",
    "n_out = 2        # Determined by our number of classes, so 2: birds and planes\n",
    "\n",
    "model_seq = nn.Sequential(\n",
    "    # Flatten is required in this case because each input is (32x32x3)\n",
    "    # dimensional and linear layers expect 1D inputs\n",
    "    nn.Flatten(),              \n",
    "    nn.Linear(n_in, n_hidden1),\n",
    "    nn.Tanh(),                   \n",
    "    nn.Linear(n_hidden1, n_hidden2),\n",
    "    nn.ReLU(),\n",
    "    nn.Linear(n_hidden2, n_out),\n",
    "    # Note that we don't need a softmax function in the output layer if we\n",
    "    # use nn.CrossEntropyLoss as the loss function\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.3 Pytorch notations and dimensions\n",
    "\n",
    "Pytorch's modules (so neural networks, layers, loss functions, etc.) expect inputs of specific dimensions. The required shape is most of the time specified in the documentation, but using their own notations. For example, for the [nn.Conv2d](https://pytorch.org/docs/stable/generated/torch.nn.Conv2d.html#torch.nn.Conv2d) layer, it is written that the input shape should be \"``((N, C_in, H, W))`` and the output shape \"``(N, C_out, H_out, W_out))``\" .  \n",
    "Here are the most common notations and their meanings:\n",
    "\n",
    "- ``N``: batch size,         (how many inputs do you feed at the same time)\n",
    "- ``C``: number of channels, (number of color channels RGB=3, RGBA=4, etc if refering to an image or the number of filters if refering to a convolutional layer)\n",
    "- ``H``: height of the image\n",
    "- ``W``: width of the image\n",
    "- ``∗``: means any number of dimensions including none \n",
    "- $_{in} / _{out}$ : as a subscript, refers to \"input\" and \"output\". e.g. $H_{in}$ for input width and $H_{out}$ for output width\n",
    "- ``L``: sequence length (for recurrent neural networks)\n",
    "- ``in_features``: number of components of the input tensor (when the input is a vector)\n",
    "- ``out_features``: number of components of the output tensor (when the output is a vector)\n",
    "\n",
    "If the input is supposed to be images, the expected input shape is usually ``(N, C_in, H_in, W_in)`` in pytorch because the first layer is either \n",
    "- a [nn.Conv2d](https://pytorch.org/docs/stable/generated/torch.nn.Conv2d.html#torch.nn.Conv2d) layer (which precisely expects ``(N, C_in, H_in, W_in)`` inputs ) \n",
    "- or a [nn.Linear](https://pytorch.org/docs/stable/generated/torch.nn.Linear.html#torch.nn.Linear) layer (which expects ``((N, in_features))`` inputs) preceded by a [nn.Flatten](https://pytorch.org/docs/stable/generated/torch.nn.Flatten.html#torch.nn.Flatten) layer (that precisely reshapes ``(N, C_in, H_in, W_in)`` inputs into ``(N, C_in*H_in*W_in)`` inputs)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Feeding one image into our custom neural network\n",
    "\n",
    "As explained in the previous paragraph, we should first make sure that our input has shape ``(N, C_in, H_in, W_in)``, or more specifically ``(1, 3, 32, 32)`` because we want a batch composed of only one (i.e. ``N=1``) RGB image (i.e. ``C_in =3``) of dimensions ``32x32`` (i.e. ``H_in = 32``, ``W_in = 32``)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of an image:                        torch.Size([3, 32, 32])\n",
      "Shape of our input batch of one image:    torch.Size([1, 3, 32, 32])\n",
      "Shape of our output batch of one image:   torch.Size([1, 2])\n",
      "Output tensor (values are just rubbish because the nn is not trained yet!):\n",
      " Ouput:  tensor([[-0.1395, -0.3130]], grad_fn=<AddmmBackward0>)\n"
     ]
    }
   ],
   "source": [
    "# Shape of an image\n",
    "print(\"Shape of an image:                       \", cifar2_train[0][0].shape)\n",
    "# Add a extra dimension for the batch dimension\n",
    "batch_t = torch.unsqueeze(cifar2_train[0][0], 0)\n",
    "print(\"Shape of our input batch of one image:   \", batch_t.shape)\n",
    "# Feed our batch into our network and get the output\n",
    "out = model_seq(batch_t)\n",
    "print(\"Shape of our output batch of one image:  \", out.shape)   \n",
    "print(\"Output tensor (values are just rubbish because the nn is not trained yet!):\\n Ouput: \", out)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.4 Inspecting a module object\n",
    "\n",
    "We saw earlier that [nn.Module](https://pytorch.org/docs/stable/generated/torch.nn.Module.html) is an essential part of the PyTorch library and that it is the base class for all the basic components of a neural network.\n",
    "The fact that so many PyTorch objects inherit from this class has many advantages. One of them is that they share many important methods such as:\n",
    "\n",
    "- [forward](https://pytorch.org/docs/stable/generated/torch.nn.Module.html#torch.nn.Module.forward) Defines the computation performed at every call. **Should be overridden by all subclasses** (We'll see that later)\n",
    "- [modules](https://pytorch.org/docs/stable/generated/torch.nn.Module.html#torch.nn.Module.modules): Returns an iterator over all modules in the network.\n",
    "- [named\\_modules](https://pytorch.org/docs/stable/generated/torch.nn.Module.html#torch.nn.Module.named_modules): Returns an iterator over all modules in the network, yielding both the name of the module as well as the module itself.\n",
    "- [parameters](https://pytorch.org/docs/stable/generated/torch.nn.Module.html#torch.nn.Module.parameters): Returns an iterator over module parameters (the so-called [nn.Parameter](https://pytorch.org/docs/stable/generated/torch.nn.parameter.Parameter.html), the subclass of Tensor)\n",
    "- [named\\_parameters](https://pytorch.org/docs/stable/generated/torch.nn.Module.html#torch.nn.Module.named_parameters): Returns an iterator over module parameters, yielding both the name of the parameter as well as the parameter itself.\n",
    "- [state_dict](https://pytorch.org/docs/stable/generated/torch.nn.Module.html#torch.nn.Module.state_dict): Returns a dictionary containing a whole state of the module (can be useful when saving a module)\n",
    "- [load\\_state\\_dict](https://pytorch.org/docs/stable/generated/torch.nn.Module.html#torch.nn.Module.load_state_dict): Copies parameters and buffers from state_dict into this module and its descendants (can be useful when loading/copying a module)\n",
    "- [to](https://pytorch.org/docs/stable/generated/torch.nn.Module.html#torch.nn.Module.to) Moves and/or casts the parameters and buffers (typically to a GPU or CPU)\n",
    "- [cpu](https://pytorch.org/docs/stable/generated/torch.nn.Module.html#torch.nn.Module.cpu) / [cuda](https://pytorch.org/docs/stable/generated/torch.nn.Module.html#torch.nn.Module.cuda): Moves all model parameters and buffers to the CPU / GPU\n",
    "- [train](https://pytorch.org/docs/stable/generated/torch.nn.Module.html#torch.nn.Module.train) / [eval](https://pytorch.org/docs/stable/generated/torch.nn.Module.html#torch.nn.Module.eval): Sets the module in training/evaluation mode\n",
    "- [zero_grad](https://pytorch.org/docs/stable/generated/torch.nn.Module.html#torch.nn.Module.zero_grad): Sets gradients of all model parameters to zero.\n",
    "\n",
    "We will use most of these methods in this tutorial already. Let's start with the ones returning parameters / modules. We also use [torch.numel](https://pytorch.org/docs/stable/generated/torch.numel.html#torch.numel) to get the total number of elements in a given tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Inspecting parameters\n",
      "name:  1.weight    length:  786432\n",
      "name:  1.bias    length:  256\n",
      "name:  3.weight    length:  16384\n",
      "name:  3.bias    length:  64\n",
      "name:  5.weight    length:  128\n",
      "name:  5.bias    length:  2\n",
      "\n",
      "Total number of trainable parameters:  803266\n",
      "\n",
      "Inspecting modules\n",
      "('', Sequential(\n",
      "  (0): Flatten(start_dim=1, end_dim=-1)\n",
      "  (1): Linear(in_features=3072, out_features=256, bias=True)\n",
      "  (2): Tanh()\n",
      "  (3): Linear(in_features=256, out_features=64, bias=True)\n",
      "  (4): ReLU()\n",
      "  (5): Linear(in_features=64, out_features=2, bias=True)\n",
      "))\n",
      "('0', Flatten(start_dim=1, end_dim=-1))\n",
      "('1', Linear(in_features=3072, out_features=256, bias=True))\n",
      "('2', Tanh())\n",
      "('3', Linear(in_features=256, out_features=64, bias=True))\n",
      "('4', ReLU())\n",
      "('5', Linear(in_features=64, out_features=2, bias=True))\n"
     ]
    }
   ],
   "source": [
    "print(\"Inspecting parameters\")\n",
    "# Iterate over all the named parameters of our network\n",
    "for p in model_seq.named_parameters():\n",
    "    # p is a tuple: \n",
    "    # - p[0] is the name of parameter\n",
    "    # - p[1] is a tensor containing the current parameter values\n",
    "    print(\"name: \", p[0], \"   length: \", p[1].numel())\n",
    "    \n",
    "\n",
    "print(\"\\nTotal number of trainable parameters: \", sum([p.numel() for p in model_seq.parameters() if p.requires_grad == True]))\n",
    "\n",
    "print(\"\\nInspecting modules\")\n",
    "# Iterate over all the named modules of our network\n",
    "for m in model_seq.named_modules():\n",
    "    print(m)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3 Training our model\n",
    "\n",
    "### 3.1 Training on CPU\n",
    "\n",
    "#### Defining the training loop \n",
    "\n",
    "*(inspired by 8.4 Training our convnet)*\n",
    "\n",
    "\n",
    "\n",
    "Links to the documentation:\n",
    "- [nn.Module.train()](https://pytorch.org/docs/stable/generated/torch.nn.Module.html#torch.nn.Module.train): Sets the module in training mode. As stated in the PyTorch documentation: \n",
    "\n",
    "> \"Some models use modules which have different training and evaluation behavior, such as batch normalization. To switch between these modes, use [model.train()](https://pytorch.org/docs/stable/generated/torch.nn.Module.html#torch.nn.Module.train) or [model.eval()](https://pytorch.org/docs/stable/generated/torch.nn.Module.html#torch.nn.Module.eval) (from the [torch.nn.Module](https://pytorch.org/docs/stable/generated/torch.nn.Module.html#module)) as appropriate.\n",
    "- [nn.Module.zero_grad](https://pytorch.org/docs/stable/generated/torch.nn.Module.html#torch.nn.Module.zero_grad): Sets gradients of all model parameters to zero.\n",
    "- [torch.autograd.Function.backward()](https://pytorch.org/docs/stable/generated/torch.autograd.Function.backward.html#torch-autograd-function-backward), backpropagates the loss\n",
    "- [torch.optim.SGD.step()](https://pytorch.org/docs/stable/generated/torch.optim.SGD.html?highlight=step#torch.optim.SGD.step), updates trainable parameters\n",
    "- [torch.Tensor.item()](https://pytorch.org/docs/stable/generated/torch.Tensor.item.html?highlight=item#torch.Tensor.item), returns the tensor's value as a standard Python number."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(n_epochs, optimizer, model, loss_fn, train_loader):\n",
    "    \n",
    "    n_batch = len(train_loader)\n",
    "    \n",
    "    # We'll store there the training loss for each epoch\n",
    "    losses_train = []\n",
    "    \n",
    "    # Set the network in training mode\n",
    "    model.train()\n",
    "    \n",
    "    # Re-initialize gradients, just in case the model has been inappropriately \n",
    "    # manipulated before the training\n",
    "    optimizer.zero_grad(set_to_none=True)\n",
    "    \n",
    "    for epoch in range(1, n_epochs + 1): \n",
    "        \n",
    "        # Training loss for the current epoch\n",
    "        loss_train = 0\n",
    "\n",
    "        # Loop over our dataset (in batches the data loader creates for us)\n",
    "        for imgs, labels in train_loader:\n",
    "            \n",
    "            # Feed a batch into our model\n",
    "            outputs = model(imgs)\n",
    "            \n",
    "            # Compute the loss we wish to minimize \n",
    "            # Note that by default, it is the mean loss that is computed\n",
    "            # (so entire_batch_loss / batch_size)\n",
    "            loss = loss_fn(outputs, labels) \n",
    "            \n",
    "            \n",
    "            # Perform the backward step. That is, compute the gradients of all parameters we want the network to learn\n",
    "            loss.backward()\n",
    "            \n",
    "            # Update the model\n",
    "            optimizer.step() \n",
    "            \n",
    "            # Zero out gradients before the next round (or the end of training)\n",
    "            optimizer.zero_grad() \n",
    "\n",
    "            # Update loss for this epoch\n",
    "            # It is important to transform the loss to a number with .item()\n",
    "            loss_train += loss.item()\n",
    "            \n",
    "        # Store current epoch loss. \n",
    "        losses_train.append(loss_train / n_batch)\n",
    "\n",
    "        if epoch == 1 or epoch % 10 == 0:\n",
    "            print('{}  |  Epoch {}  |  Training loss {:.3f}'.format(\n",
    "                datetime.now().time(), epoch, loss_train / n_batch))\n",
    "            \n",
    "    return losses_train"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Train the model using the training loop\n",
    "\n",
    "Links to the documentation:\n",
    "- [torch.utils.data.DataLoader](https://pytorch.org/docs/stable/data.html?highlight=dataloader#torch.utils.data.DataLoader), efficiently loads the dataset into batches\n",
    "- [optim.SGD](https://pytorch.org/docs/stable/generated/torch.optim.SGD.html?highlight=sgd#torch.optim.SGD), optimizer\n",
    "- [nn.CrossEntropyLoss](https://pytorch.org/docs/stable/generated/torch.nn.CrossEntropyLoss.html?highlight=crossentropy#torch.nn.CrossEntropyLoss), loss function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "08:26:27.500662  |  Epoch 1  |  Training loss 0.544\n",
      "08:26:34.727586  |  Epoch 10  |  Training loss 0.343\n",
      "08:26:43.514128  |  Epoch 20  |  Training loss 0.243\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# The DataLoader batches up the examples of our cifar dataset\n",
    "# Here we use shuffle = True in order to shuffle the dataset for the training\n",
    "train_loader = torch.utils.data.DataLoader(cifar2_train, batch_size=64, shuffle=True) \n",
    "\n",
    "# Instantiate the optimizer, here:\n",
    "# 1. Stochastic Gradient Descent optimizer, \n",
    "# 2. that has to be applied to our parameters (model.parameters())\n",
    "# 3. With a learning rate of 1e-2\n",
    "optimizer = optim.SGD(model_seq.parameters(), lr=1e-2)\n",
    "\n",
    "# Instantiate the loss function (here we use cross entropy)\n",
    "loss_fn = nn.CrossEntropyLoss()\n",
    "\n",
    "# Now all we have to do is calling the training loop\n",
    "# WARNING THIS MIGHT BE EXTREMELY SLOW. STOP YOUR KERNEL TO STOP THE TRAINING\n",
    "train(\n",
    "    n_epochs = 21,\n",
    "    optimizer = optimizer,\n",
    "    model = model_seq,\n",
    "    loss_fn = loss_fn,\n",
    "    train_loader = train_loader,\n",
    ")\n",
    "print('')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Measuring accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training accuracy:\n",
      "Accuracy: 0.91\n",
      "Validation accuracy:\n",
      "Accuracy: 0.85\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.8463886063072228"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Here we use shuffle = False\n",
    "# Because it is easier to check the predictions made.\n",
    "train_loader = torch.utils.data.DataLoader(cifar2_train, batch_size=64, shuffle=False)\n",
    "val_loader = torch.utils.data.DataLoader(cifar2_val, batch_size=64, shuffle=False)\n",
    "\n",
    "def compute_accuracy(model, loader):\n",
    "    model.eval()\n",
    "    correct = 0\n",
    "    total = 0\n",
    "\n",
    "    # We do not want gradients here, as we will not want to update the parameters.\n",
    "    with torch.no_grad():\n",
    "        for imgs, labels in loader:\n",
    "\n",
    "            outputs = model(imgs)\n",
    "            _, predicted = torch.max(outputs, dim=1)\n",
    "            total += labels.shape[0]\n",
    "            correct += int((predicted == labels).sum())\n",
    "\n",
    "    acc =  correct / total\n",
    "    print(\"Accuracy: {:.2f}\".format(acc))\n",
    "    return acc\n",
    "\n",
    "print(\"Training accuracy:\")\n",
    "compute_accuracy(model_seq, train_loader)\n",
    "print(\"Validation accuracy:\")\n",
    "compute_accuracy(model_seq, val_loader)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.2 Training on GPU\n",
    "\n",
    "*(Inspired by 8.4.3 Training on the GPU)*\n",
    "\n",
    "#### Check if a GPU is available\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training on device cpu.\n"
     ]
    }
   ],
   "source": [
    "device = (torch.device('cuda') if torch.cuda.is_available()\n",
    "          else torch.device('cpu'))\n",
    "print(f\"Training on device {device}.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Defining the training loop "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_on_gpu(n_epochs, optimizer, model, loss_fn, train_loader):\n",
    "    \n",
    "    n_batch = len(train_loader)\n",
    "    losses_train = []\n",
    "    model.train()\n",
    "    optimizer.zero_grad(set_to_none=True)\n",
    "    \n",
    "    for epoch in range(1, n_epochs + 1):\n",
    "        # Training loss for the current epoch\n",
    "        loss_train = 0.0\n",
    "        for imgs, labels in train_loader:\n",
    "            # These two lines following lines are what differs from \n",
    "            # our previous traini function.\n",
    "            # They move imgs and labels to the device we are training\n",
    "            # on (gpu if available, cpu otherwise)\n",
    "            imgs = imgs.to(device=device) \n",
    "            labels = labels.to(device=device)\n",
    "\n",
    "            outputs = model(imgs)\n",
    "            \n",
    "            loss = loss_fn(outputs, labels)\n",
    "            loss.backward()\n",
    "            \n",
    "            optimizer.step()\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "            loss_train += loss.item()\n",
    "            \n",
    "        losses_train.append(loss_train / n_batch)\n",
    "\n",
    "        if epoch == 1 or epoch % 10 == 0:\n",
    "            print('{}  |  Epoch {}  |  Training loss {:.3f}'.format(\n",
    "                datetime.now().time(), epoch, loss_train / n_batch))\n",
    "    return losses_train"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Train the model using the training loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "08:26:46.384795  |  Epoch 1  |  Training loss 0.227\n",
      "08:26:53.472497  |  Epoch 10  |  Training loss 0.147\n",
      "08:27:00.503042  |  Epoch 20  |  Training loss 0.084\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Again shuffle = True for the training phase\n",
    "train_loader = torch.utils.data.DataLoader(cifar2_train, batch_size=64, shuffle=True)\n",
    "\n",
    "# Moves our model (all parameters) to the GPU. If \n",
    "# you forget to move either the model or the inputs to the\n",
    "# GPU, you will get errors about tensors not being on the same\n",
    "# device, because the PyTorch operators do not support\n",
    "# mixing GPU and CPU inputs.\n",
    "model_seq.to(device=device) \n",
    "optimizer = optim.SGD(model_seq.parameters(), lr=1e-2)\n",
    "loss_fn = nn.CrossEntropyLoss()\n",
    "\n",
    "\n",
    "# WARNING. This is supposed to much much faster than previously but it \n",
    "# might still take a while if your gpu is not available\n",
    "# AGAIN STOP YOUR KERNEL IF IT'S TOO SLOW \n",
    "train_on_gpu(\n",
    "    n_epochs = 20,\n",
    "    optimizer = optimizer,\n",
    "    model = model_seq,\n",
    "    loss_fn = loss_fn,\n",
    "    train_loader = train_loader,\n",
    ")\n",
    "print('')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Measuring accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training accuracy:\n",
      "Accuracy: 0.98\n",
      "Validation accuracy:\n",
      "Accuracy: 0.84\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.8402848423194303"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Again shuffle = False outside training\n",
    "train_loader = torch.utils.data.DataLoader(cifar2_train, batch_size=64, shuffle=False)\n",
    "val_loader = torch.utils.data.DataLoader(cifar2_val, batch_size=64, shuffle=False)\n",
    "\n",
    "def compute_accuracy_on_gpu(model, loader):\n",
    "    model.eval()\n",
    "    correct = 0\n",
    "    total = 0\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for imgs, labels in loader:\n",
    "            # These two lines following lines are what differs from \n",
    "            # our previous validate function.\n",
    "            # They move imgs and labels to the device we are predicting\n",
    "            # on (gpu if available, cpu otherwise)\n",
    "            imgs = imgs.to(device=device)\n",
    "            labels = labels.to(device=device)\n",
    "\n",
    "            outputs = model(imgs)\n",
    "            _, predicted = torch.max(outputs, dim=1)\n",
    "            total += labels.shape[0]\n",
    "            correct += int((predicted == labels).sum())\n",
    "\n",
    "    acc =  correct / total\n",
    "    print(\"Accuracy: {:.2f}\".format(acc))\n",
    "    return acc\n",
    "\n",
    "print(\"Training accuracy:\")\n",
    "compute_accuracy_on_gpu(model_seq, train_loader)\n",
    "print(\"Validation accuracy:\")\n",
    "compute_accuracy_on_gpu(model_seq, val_loader)"
   ]
  }
 ],
 "metadata": {
  "celltoolbar": "Tags",
  "kernelspec": {
   "display_name": "inf265",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4 (main, Mar 31 2022, 08:41:55) [GCC 7.5.0]"
  },
  "vscode": {
   "interpreter": {
    "hash": "d7334498cbea74be2f983349dd0c062cc89e10cb2d32c736100e0abee6e40bc2"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
